[2024-11-24T03:26:35.697+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-11-24T03:26:35.752+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sensor_data_consumer.sensor_data_consumer manual__2024-11-24T02:55:02.785438+00:00 [queued]>
[2024-11-24T03:26:35.780+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sensor_data_consumer.sensor_data_consumer manual__2024-11-24T02:55:02.785438+00:00 [queued]>
[2024-11-24T03:26:35.780+0000] {taskinstance.py:2306} INFO - Starting attempt 3 of 1
[2024-11-24T03:26:36.010+0000] {taskinstance.py:2330} INFO - Executing <Task(SparkSubmitOperator): sensor_data_consumer> on 2024-11-24 02:55:02.785438+00:00
[2024-11-24T03:26:36.017+0000] {standard_task_runner.py:64} INFO - Started process 219 to run task
[2024-11-24T03:26:36.028+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'sensor_data_consumer', 'sensor_data_consumer', 'manual__2024-11-24T02:55:02.785438+00:00', '--job-id', '79', '--raw', '--subdir', 'DAGS_FOLDER/***_consumer.py', '--cfg-path', '/tmp/tmpz92ydm4c']
[2024-11-24T03:26:36.031+0000] {standard_task_runner.py:91} INFO - Job 79: Subtask sensor_data_consumer
[2024-11-24T03:26:36.173+0000] {task_command.py:426} INFO - Running <TaskInstance: sensor_data_consumer.sensor_data_consumer manual__2024-11-24T02:55:02.785438+00:00 [running]> on host 355cdd50bbb7
[2024-11-24T03:26:36.380+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Bich Ly' AIRFLOW_CTX_DAG_ID='sensor_data_consumer' AIRFLOW_CTX_TASK_ID='sensor_data_consumer' AIRFLOW_CTX_EXECUTION_DATE='2024-11-24T02:55:02.785438+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-24T02:55:02.785438+00:00'
[2024-11-24T03:26:36.382+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-11-24T03:26:36.433+0000] {base.py:84} INFO - Using connection ID 'spark_default' for task execution.
[2024-11-24T03:26:36.434+0000] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.4.2,org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.2,org.apache.hadoop:hadoop-client:3.2.1 --name KafkaSparkHDFS /opt/***/dags/spark_streaming_job.py
[2024-11-24T03:26:44.084+0000] {spark_submit.py:495} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-11-24T03:26:44.278+0000] {spark_submit.py:495} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2024-11-24T03:26:44.278+0000] {spark_submit.py:495} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2024-11-24T03:26:44.289+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-streaming-kafka-0-10_2.12 added as a dependency
[2024-11-24T03:26:44.290+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2024-11-24T03:26:44.291+0000] {spark_submit.py:495} INFO - org.apache.hadoop#hadoop-client added as a dependency
[2024-11-24T03:26:44.292+0000] {spark_submit.py:495} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-7354cc50-e125-4317-bde4-13f8a3dd7616;1.0
[2024-11-24T03:26:44.292+0000] {spark_submit.py:495} INFO - confs: [default]
[2024-11-24T03:26:44.694+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-streaming-kafka-0-10_2.12;3.4.2 in central
[2024-11-24T03:26:44.858+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.2 in central
[2024-11-24T03:26:44.927+0000] {spark_submit.py:495} INFO - found org.apache.kafka#kafka-clients;3.3.2 in central
[2024-11-24T03:26:44.962+0000] {spark_submit.py:495} INFO - found org.lz4#lz4-java;1.8.0 in central
[2024-11-24T03:26:44.992+0000] {spark_submit.py:495} INFO - found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2024-11-24T03:26:45.025+0000] {spark_submit.py:495} INFO - found org.slf4j#slf4j-api;2.0.6 in central
[2024-11-24T03:26:45.087+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2024-11-24T03:26:45.143+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2024-11-24T03:26:45.196+0000] {spark_submit.py:495} INFO - found commons-logging#commons-logging;1.1.3 in central
[2024-11-24T03:26:45.213+0000] {spark_submit.py:495} INFO - found com.google.code.findbugs#jsr305;3.0.0 in central
[2024-11-24T03:26:45.276+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-sql-kafka-0-10_2.12;3.4.2 in central
[2024-11-24T03:26:45.320+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-pool2;2.11.1 in central
[2024-11-24T03:26:45.360+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-client;3.2.1 in central
[2024-11-24T03:26:45.420+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-common;3.2.1 in central
[2024-11-24T03:26:45.565+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-annotations;3.2.1 in central
[2024-11-24T03:26:45.705+0000] {spark_submit.py:495} INFO - found com.google.guava#guava;27.0-jre in central
[2024-11-24T03:26:45.731+0000] {spark_submit.py:495} INFO - found com.google.guava#failureaccess;1.0 in central
[2024-11-24T03:26:45.784+0000] {spark_submit.py:495} INFO - found com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central
[2024-11-24T03:26:45.894+0000] {spark_submit.py:495} INFO - found org.checkerframework#checker-qual;2.5.2 in central
[2024-11-24T03:26:45.971+0000] {spark_submit.py:495} INFO - found com.google.errorprone#error_prone_annotations;2.2.0 in central
[2024-11-24T03:26:46.033+0000] {spark_submit.py:495} INFO - found com.google.j2objc#j2objc-annotations;1.1 in central
[2024-11-24T03:26:46.082+0000] {spark_submit.py:495} INFO - found org.codehaus.mojo#animal-sniffer-annotations;1.17 in central
[2024-11-24T03:26:46.112+0000] {spark_submit.py:495} INFO - found commons-cli#commons-cli;1.2 in central
[2024-11-24T03:26:46.129+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-math3;3.1.1 in central
[2024-11-24T03:26:46.147+0000] {spark_submit.py:495} INFO - found org.apache.httpcomponents#httpclient;4.5.6 in central
[2024-11-24T03:26:46.168+0000] {spark_submit.py:495} INFO - found org.apache.httpcomponents#httpcore;4.4.10 in central
[2024-11-24T03:26:46.190+0000] {spark_submit.py:495} INFO - found commons-codec#commons-codec;1.11 in central
[2024-11-24T03:26:46.202+0000] {spark_submit.py:495} INFO - found commons-io#commons-io;2.5 in central
[2024-11-24T03:26:46.224+0000] {spark_submit.py:495} INFO - found commons-net#commons-net;3.6 in central
[2024-11-24T03:26:46.242+0000] {spark_submit.py:495} INFO - found commons-collections#commons-collections;3.2.2 in central
[2024-11-24T03:26:46.255+0000] {spark_submit.py:495} INFO - found org.eclipse.jetty#jetty-servlet;9.3.24.v20180605 in central
[2024-11-24T03:26:46.271+0000] {spark_submit.py:495} INFO - found org.eclipse.jetty#jetty-security;9.3.24.v20180605 in central
[2024-11-24T03:26:46.301+0000] {spark_submit.py:495} INFO - found org.eclipse.jetty#jetty-webapp;9.3.24.v20180605 in central
[2024-11-24T03:26:46.317+0000] {spark_submit.py:495} INFO - found org.eclipse.jetty#jetty-xml;9.3.24.v20180605 in central
[2024-11-24T03:26:46.330+0000] {spark_submit.py:495} INFO - found com.sun.jersey#jersey-servlet;1.19 in central
[2024-11-24T03:26:46.354+0000] {spark_submit.py:495} INFO - found log4j#log4j;1.2.17 in central
[2024-11-24T03:26:46.369+0000] {spark_submit.py:495} INFO - found commons-beanutils#commons-beanutils;1.9.3 in central
[2024-11-24T03:26:46.411+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-configuration2;2.1.1 in central
[2024-11-24T03:26:46.443+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-lang3;3.7 in central
[2024-11-24T03:26:46.480+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-text;1.4 in central
[2024-11-24T03:26:46.551+0000] {spark_submit.py:495} INFO - found org.apache.avro#avro;1.7.7 in central
[2024-11-24T03:26:46.616+0000] {spark_submit.py:495} INFO - found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
[2024-11-24T03:26:46.663+0000] {spark_submit.py:495} INFO - found org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central
[2024-11-24T03:26:46.735+0000] {spark_submit.py:495} INFO - found com.thoughtworks.paranamer#paranamer;2.3 in central
[2024-11-24T03:26:46.777+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-compress;1.18 in central
[2024-11-24T03:26:46.818+0000] {spark_submit.py:495} INFO - found com.google.re2j#re2j;1.1 in central
[2024-11-24T03:26:46.844+0000] {spark_submit.py:495} INFO - found com.google.protobuf#protobuf-java;2.5.0 in central
[2024-11-24T03:26:46.857+0000] {spark_submit.py:495} INFO - found com.google.code.gson#gson;2.2.4 in central
[2024-11-24T03:26:46.908+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-auth;3.2.1 in central
[2024-11-24T03:26:46.909+0000] {spark_submit.py:495} INFO - found com.nimbusds#nimbus-jose-jwt;4.41.1 in central
[2024-11-24T03:26:46.909+0000] {spark_submit.py:495} INFO - found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2024-11-24T03:26:46.940+0000] {spark_submit.py:495} INFO - found net.minidev#json-smart;2.3 in central
[2024-11-24T03:26:46.940+0000] {spark_submit.py:495} INFO - found net.minidev#accessors-smart;1.2 in central
[2024-11-24T03:26:46.954+0000] {spark_submit.py:495} INFO - found org.ow2.asm#asm;5.0.4 in central
[2024-11-24T03:26:46.968+0000] {spark_submit.py:495} INFO - found org.apache.curator#curator-framework;2.13.0 in central
[2024-11-24T03:26:47.010+0000] {spark_submit.py:495} INFO - found org.apache.curator#curator-client;2.13.0 in central
[2024-11-24T03:26:47.038+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-simplekdc;1.0.1 in central
[2024-11-24T03:26:47.110+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-client;1.0.1 in central
[2024-11-24T03:26:47.135+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerby-config;1.0.1 in central
[2024-11-24T03:26:47.161+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-core;1.0.1 in central
[2024-11-24T03:26:47.185+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerby-pkix;1.0.1 in central
[2024-11-24T03:26:47.207+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerby-asn1;1.0.1 in central
[2024-11-24T03:26:47.230+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerby-util;1.0.1 in central
[2024-11-24T03:26:47.251+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-common;1.0.1 in central
[2024-11-24T03:26:47.265+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-crypto;1.0.1 in central
[2024-11-24T03:26:47.287+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-util;1.0.1 in central
[2024-11-24T03:26:47.307+0000] {spark_submit.py:495} INFO - found org.apache.kerby#token-provider;1.0.1 in central
[2024-11-24T03:26:47.318+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-admin;1.0.1 in central
[2024-11-24T03:26:47.380+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-server;1.0.1 in central
[2024-11-24T03:26:47.421+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerb-identity;1.0.1 in central
[2024-11-24T03:26:47.448+0000] {spark_submit.py:495} INFO - found org.apache.kerby#kerby-xdr;1.0.1 in central
[2024-11-24T03:26:47.489+0000] {spark_submit.py:495} INFO - found org.apache.curator#curator-recipes;2.13.0 in central
[2024-11-24T03:26:47.521+0000] {spark_submit.py:495} INFO - found org.apache.htrace#htrace-core4;4.1.0-incubating in central
[2024-11-24T03:26:47.541+0000] {spark_submit.py:495} INFO - found com.fasterxml.jackson.core#jackson-databind;2.9.8 in central
[2024-11-24T03:26:47.565+0000] {spark_submit.py:495} INFO - found com.fasterxml.jackson.core#jackson-annotations;2.9.8 in central
[2024-11-24T03:26:47.592+0000] {spark_submit.py:495} INFO - found com.fasterxml.jackson.core#jackson-core;2.9.8 in central
[2024-11-24T03:26:47.606+0000] {spark_submit.py:495} INFO - found org.codehaus.woodstox#stax2-api;3.1.4 in central
[2024-11-24T03:26:47.620+0000] {spark_submit.py:495} INFO - found com.fasterxml.woodstox#woodstox-core;5.0.3 in central
[2024-11-24T03:26:47.638+0000] {spark_submit.py:495} INFO - found dnsjava#dnsjava;2.1.7 in central
[2024-11-24T03:26:47.708+0000] {spark_submit.py:495} INFO - found javax.servlet.jsp#jsp-api;2.1 in central
[2024-11-24T03:26:47.788+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-hdfs-client;3.2.1 in central
[2024-11-24T03:26:47.818+0000] {spark_submit.py:495} INFO - found com.squareup.okhttp#okhttp;2.7.5 in central
[2024-11-24T03:26:47.838+0000] {spark_submit.py:495} INFO - found com.squareup.okio#okio;1.6.0 in central
[2024-11-24T03:26:47.866+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-yarn-api;3.2.1 in central
[2024-11-24T03:26:47.894+0000] {spark_submit.py:495} INFO - found javax.xml.bind#jaxb-api;2.2.11 in central
[2024-11-24T03:26:47.911+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-yarn-client;3.2.1 in central
[2024-11-24T03:26:47.975+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-mapreduce-client-core;3.2.1 in central
[2024-11-24T03:26:48.014+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-yarn-common;3.2.1 in central
[2024-11-24T03:26:48.108+0000] {spark_submit.py:495} INFO - found javax.servlet#javax.servlet-api;3.1.0 in central
[2024-11-24T03:26:48.151+0000] {spark_submit.py:495} INFO - found org.eclipse.jetty#jetty-util;9.3.24.v20180605 in central
[2024-11-24T03:26:48.182+0000] {spark_submit.py:495} INFO - found com.sun.jersey#jersey-core;1.19 in central
[2024-11-24T03:26:48.218+0000] {spark_submit.py:495} INFO - found javax.ws.rs#jsr311-api;1.1.1 in central
[2024-11-24T03:26:48.251+0000] {spark_submit.py:495} INFO - found com.sun.jersey#jersey-client;1.19 in central
[2024-11-24T03:26:48.401+0000] {spark_submit.py:495} INFO - found com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.9.8 in central
[2024-11-24T03:26:48.519+0000] {spark_submit.py:495} INFO - found com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.9.8 in central
[2024-11-24T03:26:48.556+0000] {spark_submit.py:495} INFO - found com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.9.8 in central
[2024-11-24T03:26:48.640+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-mapreduce-client-jobclient;3.2.1 in central
[2024-11-24T03:26:48.676+0000] {spark_submit.py:495} INFO - found org.apache.hadoop#hadoop-mapreduce-client-common;3.2.1 in central
[2024-11-24T03:26:53.571+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...
[2024-11-24T03:30:08.697+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (199784ms)
[2024-11-24T03:30:09.366+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...
[2024-11-24T03:30:10.809+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (2103ms)
[2024-11-24T03:30:11.528+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...
[2024-11-24T03:30:23.397+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (12571ms)
[2024-11-24T03:30:24.101+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.6/slf4j-api-2.0.6.jar ...
[2024-11-24T03:30:24.881+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.slf4j#slf4j-api;2.0.6!slf4j-api.jar (1456ms)
[2024-11-24T03:30:25.639+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...
[2024-11-24T03:32:11.903+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (107028ms)
[2024-11-24T03:32:12.564+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...
[2024-11-24T03:32:13.281+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (1369ms)
[2024-11-24T03:32:13.509+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...
[2024-11-24T03:32:14.244+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (957ms)
[2024-11-24T03:32:14.935+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...
[2024-11-24T03:32:15.785+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (1526ms)
[2024-11-24T03:32:16.466+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar ...
[2024-11-24T03:32:43.515+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-common;3.2.1!hadoop-common.jar (27717ms)
[2024-11-24T03:32:44.208+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs-client/3.2.1/hadoop-hdfs-client-3.2.1.jar ...
[2024-11-24T03:33:16.476+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs-client;3.2.1!hadoop-hdfs-client.jar (32958ms)
[2024-11-24T03:33:17.160+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/3.2.1/hadoop-yarn-api-3.2.1.jar ...
[2024-11-24T03:33:40.484+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;3.2.1!hadoop-yarn-api.jar (23995ms)
[2024-11-24T03:33:41.278+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/3.2.1/hadoop-yarn-client-3.2.1.jar ...
[2024-11-24T03:33:44.068+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;3.2.1!hadoop-yarn-client.jar (3573ms)
[2024-11-24T03:33:44.807+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.1/hadoop-mapreduce-client-core-3.2.1.jar ...
[2024-11-24T03:33:54.305+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;3.2.1!hadoop-mapreduce-client-core.jar (10231ms)
[2024-11-24T03:33:54.993+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.1/hadoop-mapreduce-client-jobclient-3.2.1.jar ...
[2024-11-24T03:33:55.777+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;3.2.1!hadoop-mapreduce-client-jobclient.jar (1471ms)
[2024-11-24T03:33:56.511+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/3.2.1/hadoop-annotations-3.2.1.jar ...
[2024-11-24T03:33:57.224+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;3.2.1!hadoop-annotations.jar (1443ms)
[2024-11-24T03:33:57.916+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar ...
[2024-11-24T03:34:08.531+0000] {local_task_job_runner.py:124} ERROR - Received SIGTERM. Terminating subprocesses
[2024-11-24T03:34:08.847+0000] {process_utils.py:132} INFO - Sending 15 to group 219. PIDs of all processes in the group: [226, 219]
[2024-11-24T03:34:08.895+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 219
[2024-11-24T03:34:08.897+0000] {taskinstance.py:2611} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-11-24T03:34:08.898+0000] {spark_submit.py:620} INFO - Sending kill signal to spark-submit
[2024-11-24T03:34:08.902+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-11-24T03:34:09.068+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 414, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 463, in _process_spark_submit_log
    for line in itr:
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2613, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2024-11-24T03:34:09.117+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=sensor_data_consumer, task_id=sensor_data_consumer, run_id=manual__2024-11-24T02:55:02.785438+00:00, execution_date=20241124T025502, start_date=20241124T032635, end_date=20241124T033409
[2024-11-24T03:34:09.448+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=226, status='terminated', started='03:26:36') (226) terminated with exit code None
[2024-11-24T03:34:09.449+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=219, status='terminated', exitcode=2, started='03:26:35') (219) terminated with exit code 2
[2024-11-24T03:34:09.449+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 143
[2024-11-24T03:34:09.569+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-11-24T03:34:11.562+0000] {local_task_job_runner.py:124} ERROR - Received SIGTERM. Terminating subprocesses
[2024-11-24T03:34:11.563+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 143
[2024-11-24T03:34:11.589+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
